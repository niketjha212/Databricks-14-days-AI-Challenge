ğ——ğ—®ğ˜†-ğŸ®: Apache Spark Fundamentals

 Things Learned:
* Spark Architecture: Understood the roles of Driver, Executors, and how Spark uses DAG (Directed Acyclic Graph) to optimize execution.
* DataFrames vs RDDs : Learned why DataFrames are preferred over RDDs due to optimization, ease of use, and Catalyst optimizer.
* Lazy Evaluation : Spark doesnâ€™t execute immediately â€” actions trigger execution, helping Spark optimize the entire workflow efficiently.
* Notebook Magic Commands :Got hands-on with Databricks magic commands like: %sql, %python, %fs for seamless multi-language execution.
* Importance of col() â€“ Used to refer to columns in PySpark for transformations, filtering, null checks, and calculations

ğ™ğ™–ğ™¨ğ™ ğ™¨ ğ™˜ğ™¤ğ™¢ğ™¥ğ™¡ğ™šğ™©ğ™šğ™™:
* Uploaded a sample e-commerce CSV file.
* Created a DataFrame using PySpark
* Performed basic operations : select(), show(), dtypes(), filter(), groupBy(), orderBy()
* Used col() to handle columns safely and perform null checks.

ğ˜¾ğ™ğ™–ğ™¡ğ™¡ğ™šğ™£ğ™œğ™šğ™¨ & ğ™¡ğ™šğ™–ğ™§ğ™£ğ™ğ™£ğ™œğ™¨:
Getting familiar with the Spark operations and understood how to handle null values in Spark DataFrames and using col() correctly for transformations and check.

Big thanks to Ashish Mishra, Sahib Musharraf ,Databricks, Codebasics, and Indian Data Club for organizing such a structured and hands-on challengeğŸ™Œ.
hashtag#DatabricksWithIDC hashtag#Databricks hashtag#BigData hashtag#PySpark hashtag#Lakehouse hashtag#DataEngineering hashtag#AIChallenge
